# Mac Terminal Code
import requests
import cv2
import paho.mqtt.client as mqtt
import numpy as np
import json
import struct, time


# Open camera
capture_device_type = 'AVCaptureDeviceTypeContinuityCamera'
vid = cv2.VideoCapture(0)

# MQTT settings
mqtt_server = "" 
mqtt_topic = ""

# Connect to MQTT broker
mqtt_client = mqtt.Client("")
mqtt_client.connect(mqtt_server)

#connect to wifi
def connect_wifi(wifi):
    station = network.WLAN(network.STA_IF)
    station.active(True)
    #mac = ubinascii.hexlify(network.WLAN().config('mac'),':').decode()
    #print("MAC " + mac)

    station.connect(wifi['ssid'], wifi['pass'])
    while not station.isconnected():
        time.sleep(1)
    print('Connection successful')
    print(station.ifconfig())

#Detect the color grean
def preprocess_frame(frame):
    # Convert the frame to HSV color space
    hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)

     # Apply Gaussian blur to reduce noise
    blurred_frame = cv2.GaussianBlur(frame, (5, 5), 0)


    # Define the green color range for the dog bone
    green_lower = np.array([60, 40, 40])  # Adjust these values based on your green color
    green_upper = np.array([80, 255, 255])

    # Create a binary mask for the green color
    green_mask = cv2.inRange(hsv_frame, green_lower, green_upper)

    # Apply morphological operations to remove noise and fill gaps
    kernel = np.ones((5, 5), np.uint8)
    green_mask = cv2.morphologyEx(green_mask, cv2.MORPH_OPEN, kernel)
    green_mask = cv2.morphologyEx(green_mask, cv2.MORPH_CLOSE, kernel)

    # Size thresholding to filter out small contours
    min_contour_area = 100  # Adjust this threshold based on the size of your green piece
    contours, _ = cv2.findContours(green_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    for contour in contours:
        if cv2.contourArea(contour) > min_contour_area:
            cv2.drawContours(frame, [contour], -1, (0, 255, 0), 2)

    return green_mask

''' code for position calculation
def calculate_position(mask):
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    if contours:
        # Get the largest contour
        largest_contour = max(contours, key=cv2.contourArea)

        # Calculate the centroid of the largest contour
        M = cv2.moments(largest_contour)
        if M["m00"] != 0:
            cx = int(M["m10"] / M["m00"])
            cy = int(M["m01"] / M["m00"])
            return cx, cy

    return None '''

''' code for bone recognition 
def recognize_features(processed_frame):
    # Find contours in the processed frame
    contours, _ = cv2.findContours(processed_frame, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # Loop through the contours and check for a dog bone shape
    for contour in contours:
        perimeter = cv2.arcLength(contour, True)
        approx = cv2.approxPolyDP(contour, 0.04 * perimeter, True)

        # Check if the contour has four vertices (approximates a rectangle)
        if len(approx) == 4:
            return True, cv2.contourArea(contour)  # Dog bone shape detected and area

    return False, 0  # Dog bone shape not detected

'''

# Calculate the area of the green blob
def recognize_features(processed_frame):
    # Find contours in the processed frame
    contours, _ = cv2.findContours(processed_frame, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    total_area = 0

    # Loop through the contours
    for contour in contours:
        total_area += cv2.contourArea(contour)

    return total_area

#Calcultae the angle the camera is detecting the green bone
def calculate_orientation(mask):
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    if contours:
        # Get the largest contour
        largest_contour = max(contours, key=cv2.contourArea)

        # Fit an ellipse around the contour
        if len(largest_contour) >= 5:
            ellipse = cv2.fitEllipse(largest_contour)
            orientation = ellipse[2]

            return orientation

    return None


# Initialize variables for area calculation
prev_area = 0
item_picked_up = False
mqtt_client.publish(mqtt_topic, "start") #Start the crane

while True:
    ret, frame = vid.read()

    # Detect the specified color (green)
    green_mask = preprocess_frame(frame)

    # Calculate the orientation of the green color
    orientation = calculate_orientation(green_mask)

    # Display the original frame and green color-detected result
    cv2.imshow('Original Frame', frame)
    cv2.imshow('Green Color Detection', green_mask)

    if orientation is not None:
        print(f"Orientation: {orientation} degrees")

        # Check if the color is detected at approximately 45 degrees (y direction). Change if necessary.
        if 40 < orientation < 55:
            print("Color detected at ~45 degrees.")
            item_detected = True
            mqtt_client.publish(mqtt_topic, "stop")  # Send MQTT message to stop

            # Introduce a delay of 15 seconds to give time before the next operation starts
            #time.sleep(15)

            # Detect if the item is picked up by the crane
            current_area = recognize_features(green_mask)


            # Print the current and previous areas
            print("Current Area:", current_area)
            print("Previous Area:", prev_area)

            # Compare current area with previous area to check if it's increasing
            if current_area > prev_area:
                print("Item was picked up! Area:", current_area)
                mqtt_client.publish(mqtt_topic, "area_increasing")  # Send MQTT message for area increasing
            else:
                print("Item was not picked up or area not increasing. Area:", current_area)
                mqtt_client.publish(mqtt_topic, "area_not_increasing")  # Send MQTT message for area not increasing

            # Update previous area
            prev_area = current_area
            
    # Check for user input to exit the loop
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release the video capture and close windows
vid.release()
cv2.destroyAllWindows()
